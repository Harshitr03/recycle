{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add94922-1c8e-4dc5-b9aa-287838b924c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchmetrics) (2.1.1)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchmetrics) (24.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchmetrics) (2.4.1+cu118)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchmetrics) (0.11.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2024.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mclor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from tqdm import tqdm\n",
    "!pip install torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff40d643-aa2c-4333-a26c-f9b0763a3c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule():\n",
    "    def __init__(self,batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size=batch_size\n",
    "        # We define some augmentations that we would like to apply during training\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomCrop(224, 4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "        # During validation we need to only normalize and resize\n",
    "        self.val_transform = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "        # This function sets up our datasets\n",
    "    # which includes downloading and applying the augmentations\n",
    "    def prepare_data(self):\n",
    "        from torchvision import datasets, transforms\n",
    "        #transform = transforms.Compose([\n",
    "         #   transforms.Resize((224, 224)),\n",
    "          #  transforms.ToTensor(),\n",
    "        #])\n",
    "        self.train_set = datasets.ImageFolder(root=r\"C:\\Users\\mclor\\Desktop\\Dataset\\train\" ,transform=self.train_transform)\n",
    "        self.val_set = datasets.ImageFolder(root=r\"C:\\Users\\mclor\\Desktop\\Dataset\\val\" ,transform=self.train_transform)\n",
    "\n",
    "    # This functions sets up the data loaders\n",
    "    def setup(self):\n",
    "        self.train_data_loader = torch.utils.data.DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True)\n",
    "        self.val_data_loader = torch.utils.data.DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    # This is simply a getter function for the training data loader\n",
    "    def train_dataloader(self):\n",
    "        return self.train_data_loader\n",
    "\n",
    "    # This is simply a getter function for the validation data loader\n",
    "    def val_dataloader(self):\n",
    "        return self.val_data_loader\n",
    "\n",
    "def load_image_from_url(path):\n",
    "            img = Image.open(path)  # Load image directly from URL\n",
    "            img = img.convert('RGB')  # Ensure 3 channels for ResNet\n",
    "            img = transform(img)  # Apply transformations\n",
    "            img = img.unsqueeze(0).to(\"cuda\")\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "471a45aa-c59e-4ed5-93c4-3aa867ba41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "class DLModel(nn.Module):\n",
    "    def __init__(self, num_classes=8, pretrained=True, num_unfreeze_layers=0):\n",
    "        super().__init__()\n",
    "        # Load the ResNet50 backbone, pretrained if specified\n",
    "        if pretrained:\n",
    "            self.backbone = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "            self.backbone.requires_grad_(False)\n",
    "            \n",
    "            # Unfreeze some layers if requested\n",
    "            if num_unfreeze_layers > 0:\n",
    "                num_layers = 0\n",
    "                for name, module in self.named_modules():\n",
    "                    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear) or isinstance(module, nn.BatchNorm2d):\n",
    "                        num_layers += 1\n",
    "                start_unfreezing_counter, counter = num_layers - num_unfreeze_layers, 0\n",
    "                for name, module in self.named_modules():\n",
    "                    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear) or isinstance(module, nn.BatchNorm2d):\n",
    "                        counter += 1\n",
    "                    if counter >= start_unfreezing_counter:\n",
    "                        module.requires_grad_(True)\n",
    "        else:\n",
    "            # Initialize ResNet50 from scratch\n",
    "            self.backbone = resnet50(weights=None)\n",
    "            self.backbone.requires_grad_(True)\n",
    "        self.train_acc1, self.val_acc1 = Accuracy(task=\"multiclass\", num_classes=num_classes), Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        #self.train_acc5, self.val_acc5 = Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=5), Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=5)\n",
    "        # Remove the original FC layer (ResNet50 output size is 2048)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original FC layer\n",
    "        \n",
    "        # Add more Conv2D layers after the ResNet backbone\n",
    "        self.additional_convs = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2048, out_channels=1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(in_channels=512,out_channels=256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            # Remove AdaptiveAvgPool2d here\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Fully connected layer for classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 128),  # Linear layer with 512 input (from conv output) to 256 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Dropout to prevent overfitting\n",
    "            nn.Linear(128, num_classes)  # Final output layer for classification into 'num_classes'\n",
    "        )\n",
    "\n",
    "        # Define loss function and metrics\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.train_acc1 = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc1 = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "    \n",
    "    def configure_optimizers(self, lr, momentum, max_epochs):\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=lr, momentum=momentum)\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=max_epochs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the ResNet backbone\n",
    "        x = self.backbone(x)  # Output shape: [batch_size, 2048]\n",
    "        \n",
    "        # Reshape to [batch_size, 2048, 1, 1] for additional conv layers\n",
    "        x = x.unsqueeze(-1).unsqueeze(-1)  # Add spatial dimensions\n",
    "    \n",
    "        # Forward pass through additional conv layers\n",
    "        x = self.additional_convs(x)\n",
    "    \n",
    "        # Flatten and pass through classifier\n",
    "        out = self.classifier(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "    def training_step(self, x, y):\n",
    "        self.optimizer.zero_grad()\n",
    "        preds = self.forward(x)\n",
    "        self.train_acc1.update(preds, y)\n",
    "        loss = self.criterion(preds, y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def on_training_epoch_end(self, loss, epoch):\n",
    "        acc1 = self.train_acc1.compute().item()\n",
    "        print(f\"Epoch No: {epoch+1}\\nTraining Loss: {loss}\\n Training Accuracy: {acc1}\")\n",
    "        return acc1\n",
    "\n",
    "    def validation_step(self, x, y):\n",
    "        preds = self.forward(x)\n",
    "        self.val_acc1.update(preds, y)\n",
    "        loss = self.criterion(preds, y)\n",
    "        return loss.item()\n",
    "\n",
    "    def on_validation_epoch_end(self, loss, epoch):\n",
    "        acc1 = self.val_acc1.compute().item()\n",
    "        print(f\"Validation Loss: {loss}\\nValidation Accuracy: {acc1} (Top-1)\")\n",
    "        return acc1\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        self.train_acc1.reset(), self.val_acc1.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b6111f-ca82-4151-bcae-02d22ab36405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [03:33<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 1\n",
      "Training Loss: 0.6741584238253142\n",
      " Training Accuracy: 0.8736321926116943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:17<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5859400100178189\n",
      "Validation Accuracy: 0.9092422723770142 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:55<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 2\n",
      "Training Loss: 0.16522385877998252\n",
      " Training Accuracy: 0.9733850955963135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.40920399129390717\n",
      "Validation Accuracy: 0.9358867406845093 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:55<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 3\n",
      "Training Loss: 0.10000549209745306\n",
      " Training Accuracy: 0.9831274151802063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4103473917477661\n",
      "Validation Accuracy: 0.9375520348548889 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:54<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 4\n",
      "Training Loss: 0.0720694980339\n",
      " Training Accuracy: 0.9882809519767761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.21650787882713807\n",
      "Validation Accuracy: 0.9417152404785156 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:57<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 5\n",
      "Training Loss: 0.05800574033668167\n",
      " Training Accuracy: 0.9894810914993286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2001165101925532\n",
      "Validation Accuracy: 0.9383846521377563 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:55<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 6\n",
      "Training Loss: 0.04378290543038594\n",
      " Training Accuracy: 0.9930815100669861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2829515767128517\n",
      "Validation Accuracy: 0.9417152404785156 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:56<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 7\n",
      "Training Loss: 0.03913615930237268\n",
      " Training Accuracy: 0.9925873875617981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.22739595774975088\n",
      "Validation Accuracy: 0.9417152404785156 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:56<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 8\n",
      "Training Loss: 0.03390413780549639\n",
      " Training Accuracy: 0.9937168955802917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.19790479044119516\n",
      "Validation Accuracy: 0.940049946308136 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:56<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 9\n",
      "Training Loss: 0.025695367564300173\n",
      " Training Accuracy: 0.9967525601387024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2005795629746798\n",
      "Validation Accuracy: 0.9483763575553894 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:55<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 10\n",
      "Training Loss: 0.022064219763208378\n",
      " Training Accuracy: 0.9968231320381165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1927260036787225\n",
      "Validation Accuracy: 0.9392173290252686 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:57<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 11\n",
      "Training Loss: 0.02190737024341759\n",
      " Training Accuracy: 0.9960466027259827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.20724187183400822\n",
      "Validation Accuracy: 0.9433805346488953 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:55<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 12\n",
      "Training Loss: 0.01942713910125588\n",
      " Training Accuracy: 0.9971761107444763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.18078316212631762\n",
      "Validation Accuracy: 0.940049946308136 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:54<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 13\n",
      "Training Loss: 0.016012356435193827\n",
      " Training Accuracy: 0.9978821277618408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2266317837768131\n",
      "Validation Accuracy: 0.9342215061187744 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:56<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 14\n",
      "Training Loss: 0.01381423053772826\n",
      " Training Accuracy: 0.9980939030647278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:11<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.19494361103150165\n",
      "Validation Accuracy: 0.9458784461021423 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [02:58<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 15\n",
      "Training Loss: 0.01422140042444593\n",
      " Training Accuracy: 0.9980939030647278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:18<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.20422803613150287\n",
      "Validation Accuracy: 0.9408826231956482 (Top-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import pickle\n",
    "# First define some static variables\n",
    "num_classes = 8\n",
    "num_epochs = 15\n",
    "batch_size = 150\n",
    "# Fine-tuning and training from scratch require different sets of learning rates\n",
    "lr_finetune, lr_scratch = 0.001, 0.1\n",
    "momentum = 0.9\n",
    "device = torch.device(\"cuda\")\n",
    "# This variable will be used to save the per-epoch validation accuracy\n",
    "shallow_finetuning_val_acc = list()\n",
    "# This variable will be used to save the per-epoch training loss\n",
    "shallow_finetuning_train_loss = list()\n",
    "\n",
    "# Define the data\n",
    "data_module = DataModule(batch_size=batch_size)\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "train_loader, val_loader = data_module.train_dataloader(), data_module.val_dataloader()\n",
    "\n",
    "model = DLModel(num_classes=num_classes, pretrained=True, num_unfreeze_layers=0).to(device)\n",
    "model.configure_optimizers(lr=lr_finetune, momentum=momentum, max_epochs=num_epochs)\n",
    "for epoch in range(num_epochs):\n",
    "    # This is the training cycle\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    # Iterate over each batch and update the model\n",
    "    for x, y in tqdm(train_loader, total=len(train_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        avg_loss+= model.training_step(x, y)\n",
    "    avg_loss/=len(train_loader)\n",
    "    shallow_finetuning_train_loss.append(avg_loss)\n",
    "    acc1 = model.on_training_epoch_end(avg_loss, epoch)\n",
    "\n",
    "    # This is the validation cycle\n",
    "    model.eval()\n",
    "    avg_loss = 0\n",
    "    # Iterate over each batch and get the predictions\n",
    "    for x, y in tqdm(val_loader, total=len(val_loader)):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        avg_loss+= model.validation_step(x, y)\n",
    "    avg_loss/=len(val_loader)\n",
    "    acc1 = model.on_validation_epoch_end(avg_loss, epoch)\n",
    "    shallow_finetuning_val_acc.append(acc1)\n",
    "\n",
    "    # Finally reset the metrics before going on to the next epoch\n",
    "    model.reset_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68421d-6d0a-48dc-baf7-7ea5c99ec8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
